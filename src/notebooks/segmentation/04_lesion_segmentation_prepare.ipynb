{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Lesion Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already preprocessed picai data and private data. But we need to copy them for training and testing. Also we need to create dataset.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_create_dataset_json(source_directory, destination_directory, task): \n",
    "\n",
    "    test_dir = os.path.join(destination_directory,\"imagesTs\")\n",
    "    # Ensure the source directory exists\n",
    "    if os.path.exists(source_directory) and os.path.isdir(source_directory):\n",
    "        # Ensure the destination directory exists, create it if not\n",
    "        if not os.path.exists(test_dir):\n",
    "            os.makedirs(test_dir)\n",
    "\n",
    "        # Get a list of all files in the source directory\n",
    "        files = [f for f in os.listdir(source_directory) if os.path.isfile(os.path.join(source_directory, f))]\n",
    "\n",
    "        # Copy each file to the destination directory\n",
    "        for file in files:\n",
    "            source_file_path = os.path.join(source_directory, file)\n",
    "            destination_file_path = os.path.join(test_dir, file)\n",
    "            shutil.copy2(source_file_path, destination_file_path)  # shutil.copy2 preserves metadata\n",
    "\n",
    "        print(\"Files copied successfully.\")\n",
    "    else:\n",
    "        print(\"Source directory does not exist.\")\n",
    "\n",
    "    context = {\n",
    "        \"task\": task,\n",
    "        \"description\": \"bpMRI scans from PI-CAI dataset to train nnUNet baseline\",\n",
    "        \"tensorImageSize\": \"4D\",\n",
    "        \"reference\": \"\",\n",
    "        \"licence\": \"\",\n",
    "        \"release\": \"1.0\",\n",
    "        \"channel_names\": {\n",
    "            \"0\": \"T2W\",\n",
    "            \"1\": \"ADC\",\n",
    "            \"2\": \"HBV\"\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"background\": 0,\n",
    "            \"gg1\": 1,\n",
    "            \"gg2\": 2,\n",
    "            \"gg3\": 3,\n",
    "            \"gg4\": 4,\n",
    "            \"gg5\": 5\n",
    "        },\n",
    "        \"name\": \"Hum_AI\",\n",
    "        \"numTraining\": 0,\n",
    "        \"training\": [],\n",
    "        \"numTest\": 0,\n",
    "        \"test\": [],\n",
    "        \"file_ending\": \".nii.gz\"\n",
    "    }\n",
    "\n",
    "    labels = os.listdir(os.path.join(destination_directory,\"labelsTr\"))\n",
    "    context[\"numTraining\"] = len(labels)\n",
    "    for label in labels:\n",
    "        context_data = {\n",
    "            \"image\": f\"./imagesTr/{label}\",\n",
    "            \"label\": f\"./labelsTr/{label}\"\n",
    "            }\n",
    "        context[\"training\"].append(context_data)\n",
    "    test_files = os.listdir(test_dir)\n",
    "    patients = set()\n",
    "    for file in test_files: \n",
    "        patients.add(file[:-12])\n",
    "    context['numTest'] = len(patients)\n",
    "    context['test'] = [f\"./imagesTs/{i}.nii.gz\" for i in patients]\n",
    "    with open(os.path.join(destination_directory,\"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(context, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"/local_ssd/practical_wise24/prostate_cancer/NNUNet_Lesion/Private_Dataset_Preprocessed_2/Private_Dataset/imagesTr\"\n",
    "\n",
    "task = \"Dataset600_Hum_AI\"\n",
    "\n",
    "destination_directory = f\"/local_ssd/practical_wise24/prostate_cancer/NNUNet_Lesion/nnUNet_raw/{task}\"\n",
    "copy_and_create_dataset_json(source_directory,destination_directory,task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_create_dataset_json_777(source_directory, destination_directory, task): \n",
    "\n",
    "    test_dir = os.path.join(destination_directory,\"imagesTs\")\n",
    "    # Ensure the source directory exists\n",
    "    if os.path.exists(source_directory) and os.path.isdir(source_directory):\n",
    "        # Ensure the destination directory exists, create it if not\n",
    "        if not os.path.exists(test_dir):\n",
    "            os.makedirs(test_dir)\n",
    "\n",
    "        # Get a list of all files in the source directory\n",
    "        files = [f for f in os.listdir(source_directory) if os.path.isfile(os.path.join(source_directory, f))]\n",
    "\n",
    "        # Copy each file to the destination directory\n",
    "        for file in files:\n",
    "            source_file_path = os.path.join(source_directory, file)\n",
    "            destination_file_path = os.path.join(test_dir, file)\n",
    "            shutil.copy2(source_file_path, destination_file_path)  # shutil.copy2 preserves metadata\n",
    "\n",
    "        print(\"Files copied successfully.\")\n",
    "    else:\n",
    "        print(\"Source directory does not exist.\")\n",
    "\n",
    "    context = {\n",
    "        \"task\": task,\n",
    "        \"description\": \"bpMRI scans from PI-CAI dataset to train nnUNet baseline\",\n",
    "        \"tensorImageSize\": \"4D\",\n",
    "        \"reference\": \"\",\n",
    "        \"licence\": \"\",\n",
    "        \"release\": \"1.0\",\n",
    "        \"channel_names\": {\n",
    "            \"0\": \"T2W\",\n",
    "            \"1\": \"CT\",\n",
    "            \"2\": \"HBV\"\n",
    "        },\n",
    "        \"labels\": {\n",
    "            \"background\": 0,\n",
    "            \"gg1\": 1,\n",
    "            \"gg2\": 2,\n",
    "            \"gg3\": 3,\n",
    "            \"gg4\": 4,\n",
    "            \"gg5\": 5\n",
    "        },\n",
    "        \"name\": \"ProstateLesion\",\n",
    "        \"numTraining\": 0,\n",
    "        \"training\": [],\n",
    "        \"numTest\": 0,\n",
    "        \"test\": [],\n",
    "        \"file_ending\": \".nii.gz\"\n",
    "    }\n",
    "\n",
    "    labels = os.listdir(os.path.join(destination_directory,\"labelsTr\"))\n",
    "    context[\"numTraining\"] = len(labels)\n",
    "    for label in labels:\n",
    "        context_data = {\n",
    "            \"image\": f\"./imagesTr/{label}\",\n",
    "            \"label\": f\"./labelsTr/{label}\"\n",
    "            }\n",
    "        context[\"training\"].append(context_data)\n",
    "    test_files = os.listdir(test_dir)\n",
    "    patients = set()\n",
    "    for file in test_files: \n",
    "        patients.add(file[:-12])\n",
    "    context['numTest'] = len(patients)\n",
    "    context['test'] = [f\"./imagesTs/{i}.nii.gz\" for i in patients]\n",
    "    with open(os.path.join(destination_directory,\"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(context, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"/local_ssd/practical_wise24/prostate_cancer/NNUNet_Lesion/Private_Dataset_Preprocessed_2/Private_Dataset/imagesTr\"\n",
    "task = \"Dataset777_ProstateLesion\"\n",
    "\n",
    "destination_directory = f\"/local_ssd/practical_wise24/prostate_cancer/NNUNet_Lesion/nnUNet_raw/{task}\"\n",
    "copy_and_create_dataset_json_777(source_directory,destination_directory,task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its ready to run lesion training and testing. For training go to /src and run sbatch run_training_picai.sh This will take around 5 days.\n",
    "\n",
    "For inference run sbatch run_lesion_inference.sh This will take 10-20 minutes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
