{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchio as tio\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "from dataset.Dataset import OneSliceDataset, TranformedMaskedDataset\n",
    "from encoder.encoder_decoder_model import Encoder, Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample from dataset\n",
    "modalities = \"t2w+adc+pet+mask\"\n",
    "transform = tio.RescaleIntensity(out_min_max=(0, 1), percentiles=(0, 99.5))\n",
    "dataset = OneSliceDataset(root_dir=\"../../data\", modality_transform=transform)\n",
    "img_id = 3\n",
    "img = dataset[img_id][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reconstructed image\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load(\"../encoder/checkpoints/encoder.pth\"))\n",
    "model.eval()\n",
    "\n",
    "data = torch.tensor(img)\n",
    "data = data.unsqueeze(0)\n",
    "data = data.squeeze(dim=2).float()\n",
    "print(\"d:\", data.size())\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize before and after\n",
    "def plot_slice(image):\n",
    "\n",
    "    num_channels = image.shape[0]\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        slice_img = image[channel,0,:,:]\n",
    "        plt.subplot(1, num_channels, channel + 1)  # Rows, columns, index\n",
    "        plt.imshow(slice_img, cmap=plt.cm.Greys_r)\n",
    "\n",
    "        plt.title(f'{modalities.split(\"+\")[channel].upper()}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"Original Image\")\n",
    "plot_slice(img)\n",
    "print(\"Reconstructed Image\")\n",
    "output_img = output.detach().numpy()\n",
    "output_img = np.expand_dims(output_img, axis=2)\n",
    "output_img = np.squeeze(output_img, axis=0)\n",
    "plot_slice(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Encoded Image\n",
    "\n",
    "encoded_images = model.encoder(data)\n",
    "\n",
    "print(encoded_images.size())\n",
    "\n",
    "def plot_encoded(image):\n",
    "\n",
    "    num_channels = image.shape[1]\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        slice_img = image[0,channel,:,:]\n",
    "        plt.subplot(math.ceil(num_channels / 10), 10, channel + 1)  # Rows, columns, index\n",
    "        plt.imshow(slice_img, cmap=plt.cm.Greys_r)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_encoded(encoded_images.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProstateCancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
